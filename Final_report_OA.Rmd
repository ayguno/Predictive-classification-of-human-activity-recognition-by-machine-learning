---
title: "Final_report"
author: "Ozan Aygun"
date: "4/3/2017"
output: html_document
---

# Summary


# Data loading and partitioning

Download the data sets:

```{r,results='markup',eval=FALSE}
fileURLTrain <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
fileURLTest <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileURLTrain,"train.csv")
download.file(fileURLTest,"test.csv")
```

Load the datasets:

```{r,results='markup',eval=FALSE}
training <- read.csv("train.csv")
final_testing <- read.csv("test.csv")
```

Understanding the classes:

Based on the original data description, we notice that the **classe** variable is the outcome variable representing: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

We will use the training set to build a predictive model in order to classify the cases in the final_testing set.

We therefore partition the **training set** into:

- **building**: actual model building set
- **tune.testing**: testing set for tuning the build models
- **validation**: for one-time evaluation of the model performance

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
library(caret);library(ggplot2); set.seed(23445)
INbuilding <- createDataPartition(y = training$classe,p=0.6,list = FALSE)
building <- training[INbuilding,]

rest <- training[-INbuilding,]

INtune <- createDataPartition(y = rest$classe,p=0.5,list = FALSE)
tune.testing <- rest[INtune,]
validation <- rest[-INtune,]
```

# Data cleaning, dimension reduction and exploratory analysis

** All data processing and exploration initially performed in the building set, then exactly applied to tune.testing,validation, and final_testing sets with the same parameters.**

## STEP1: Handling missing values

Note that classes are slightly unbalanced, we have more of class A.

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
table(building$classe) 
apply(is.na(building),2,sum)
length(which(apply(is.na(building),2,sum)>0)) 
```

Note that 11548 data points (98% of them) are consistently missing in 67 variables. 

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
table(building$classe[is.na(building$amplitude_pitch_forearm)])/table(building$classe) 
```
The missing values seem to be balanced between the classes, similar fraction of classes are contained in missing values.

Therefore, drop the missing value containing columns as they unlikely to contribute our predictive power.
```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
tune.testing <- tune.testing[,-which(apply(is.na(building),2,sum)>0)]
validation <- validation[,-which(apply(is.na(building),2,sum)>0)]
final_testing <- final_testing[,-which(apply(is.na(building),2,sum)>0)]
building <- building[,-which(apply(is.na(building),2,sum)>0)]
```

## STEP 2: Remove near-zero variance features

Therefore, drop the missing value containing columns as they unlikely to contribute our predictive power.
```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
nsv <- nearZeroVar(x = building, saveMetrics = TRUE)
sum(!nsv$nzv)  
```
59 of the 93 remaining features have non-zero variance and will be kept the data sets.
```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
tune.testing <- tune.testing[,!nsv$nzv]
validation <- validation[,!nsv$nzv]
final_testing <- final_testing[,!nsv$nzv]
building <- building[,!nsv$nzv] 
```

## Exploratory data analysis

####Investigating collinear features

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE}
cont <- !sapply(building,is.factor) # Continuous variables in the building set
M <- abs(cor(building[,cont])) # M is an absolute value correlation matrix representing the pairwise #correlations between all continuous variables 
diag(M) <- 0 # We replace the diagonal values with zero (just because these are the correations with  #themselves we are not interested in capturing them).
which(M > 0.8, arr.ind = TRUE) # What are the highest correated variables?
unique(row.names(which(M > 0.8, arr.ind = TRUE)))  
```

We find that there are 18 highly correlated predictiors in the data set. If we further explore one of them:

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE, fig.align='center'}
qplot(building[,row.names(M)[7]],building[,colnames(M)[5]], color = classe, data = building)+theme_bw()
```

#### Principal components analysis (PCA)

We perform PCA to see if dimension reduction might help to resolve classes in the case of collinear features:

```{r,results='markup', message=FALSE,warning=FALSE,cache=TRUE, fig.align='center'}
cor.variables <- building[,unique(row.names(which(M > 0.8, arr.ind = TRUE)))]
cor.variables$classe <- building$classe

prePCA <- preProcess(cor.variables[,-19],method = "pca")
PCAcor <- predict(prePCA,cor.variables[,-19])
qplot(PCAcor$PC1,PCAcor$PC2, color = classe, data = cor.variables) +theme_bw()
```

We concluded that there is no obvious advantage gained by calculating principal components for the collinear features. Importantly, we notice that the correlated predictors have already clusters within them. In this case, we will not attempt further dimension reduction, because the data looks like suitable for classification algorithms (rather than linear models).

# Model training, testing and stacking

# Final model validation: prediction of 20 test cases