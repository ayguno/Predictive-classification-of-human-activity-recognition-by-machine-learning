newdata <- data.frame(TotalIntench2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)
predict(modCART,newdata)
newdata <- testing[which(testing$TotalIntench2 == 23000,
testing$FiberWidthCh1 == 10,
testing$PerimStatusCh1==2),]
predict(modCART,newdata)
newdata <- testing[which(testing$TotalIntench2 == 23000 &
testing$FiberWidthCh1 == 10 &
testing$PerimStatusCh1==2),]
predict(modCART,newdata)
[which(testing$TotalIntench2 == 23000 &
testing$FiberWidthCh1 == 10 &
testing$PerimStatusCh1==2)
predictions <- predict(modCART,newdata = testing)
testing$predictions <- predictions
names(testing)
head(testing$TotalIntenCh1)
library(dplyr)
names(testing)
library(dplyr)
select(testing,TotalIntenCh2 == 23000, FiberWidthCh1 == 10, PerimStatusCh1 == 2)
library(dplyr)
filter(testing,TotalIntenCh2 == 23000 & FiberWidthCh1 == 10 & PerimStatusCh1 == 2)
testing$FiberWidthCh1
library(dplyr)
filter(testing,TotalIntenCh2 == 23000 & FiberWidthCh1 == 10.00000 & PerimStatusCh1 == 2)
library(dplyr)
filter(testing,TotalIntenCh2 == 23000 )
library(dplyr)
which(testing$TotalIntenCh2 == 23000 )
predict(modCART,newdata = data.frame(TotalIntenCh2 = 23,000, FiberWidthCh1 = 10, PerimStatusCh1=2))
predict(modCART,newdata = data.frame(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2))
which(segmentationOriginal$FiberWidthCh1 == 10)
new.data.set = testing[0,]
View(new.data.set)
new.data.set = testing[NA,]
View(newdata)
View(new.data.set)
new.data.set = testing[0,]
new.data.set = testing[0,]
predict(modCART,testing(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2))
new.data.set = testing[0,]
predict(modCART,testing[,c(TotalIntenCh2 = 23000, FiberWidthCh1 = 10, PerimStatusCh1=2)])
summarize(testing$TotalIntenCh1)
summary(testing$TotalIntenCh1)
View(new.data.set)
new.data.set = testing[0,]
new.data.set$TotalIntenCh1 = 23000
new.data.set$FiberWidthCh1 = 10
new.data.set$PerimStatusCh1 =2
predict(modCART,new.data.set)
View(new.data.set)
new.data.set = testing[0,]
new.data.set$TotalIntenCh1 = 23000
new.data.set$FiberWidthCh1 = 10
new.data.set$PerimStatusCh1 =2
new.data.set = testing[0,]
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
predict(modCART,new.data.set)
new.data.set = testing[0,]
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
new.data.set = data.frame(NA); names(new.data.set) = names(testing)
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
View(new.data.set)
new.data.set = testing[1,]
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
View(new.data.set)
new.data.set = testing[1,]; new.data.set[1,] = NA
View(new.data.set)
new.data.set = testing[1,]; new.data.set[1,] = NA
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
predict(modCART,new.data.set)
new.data.set = testing[1,]; new.data.set[1,] = 0
new.data.set$TotalIntenCh1[1] = 23000
new.data.set$FiberWidthCh1[1] = 10
new.data.set$PerimStatusCh1[1] =2
predict(modCART,new.data.set)
plot(modCART$finalModel)
print(modCART$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modOlive <- train(Area ~ ., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modOlive,newdata)
summary(olive)
colMeans(olive)
t(colMeans(olive))
as.data.frame(t(colMeans(olive)))
newdata = as.data.frame(t(colMeans(olive)))
predict(modOlive,newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(trainSA)
names(trainSA)
set.seed(13234)
modCHD <- train(factor(chd) ~ tobacco+ldl+adiposity+typea+obesity+alcohol+age, data = trainSA,
metgod = "glm", family = "binomial")
print(modCHD)
set.seed(13234)
modCHD <- train(factor(chd) ~ tobacco+ldl+adiposity+typea+obesity+alcohol+age, data = trainSA,
method = "glm", family = "binomial")
print(modCHD)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values
)/length(values)}
missClass(values = trainSA$chd,prediction = predict(modCHD,training,scale="response"))
missClass(values = trainSA$chd,prediction = predict(modCHD,trainSA,scale="response"))
missClass(values = trainSA$chd,prediction = modCHD$finalModel$fitted.values)
missClass(values = testSA$chd,prediction = modCHD$finalModel$fitted.values)
missClass(values = testSA$chd,predict(modCHD,testSA))
missClass(values = testSA$chd,predict(modCHD,testSA,type = "response"))
modCHD$finalModel$fitted.values
missClass(trainSA$chd,predict(modCHD,trainSA,type ="response"))
missClass(trainSA$chd,predict(modCHD,trainSA,type ="prob"))
missClass(trainSA$chd,predict(modCHD,trainSA,type ="raw"))
missClass(trainSA$chd,modCHD$finalModel$fitted.values)
missClass(values = testSA$chd,predict(modCHD,newdata = testSA,type = "prob"))
missClass(values = testSA$chd,predict(modCHD,newdata = testSA))
set.seed(13234)
modCHD <- train(chd ~ tobacco+ldl+adiposity+typea+obesity+alcohol+age, data = trainSA,
method = "glm", family = "binomial")
print(modCHD)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values
)/length(values)}
missClass(trainSA$chd,modCHD$finalModel$fitted.values)
missClass(values = testSA$chd,predict(modCHD,newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
y
vovel.train
vowel.train
vowel.test
View(vowel.train)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
View(vowel.train)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- train(y ~ ., data = vowel.train, method = "rf")
print(modRF)
randomForest::importance(modRF)
randomForest::varImpPlot(modRF)
varImp(modRF)
randomForest::varImpPlot(modRF)
varImp(modRF)
plot(varImp(modRF))
randomForest()
randomForest(modRF)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train)
print(modRF)
importance(modRF)
plot(varImp(modRF))
importance(modRF)
varImpPlot(modRF)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(caret)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train)
print(modRF)
library(randomForest)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train)
print(modRF)
importance(modRF)
varImpPlot(modRF)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- train(y ~ ., data = vowel.train, method= "rf", trControl = trainControl(method = "cv"))
print(modRF)
varImp(modRF)
plot(varImp(modRF))
varImp.radomForest(modRF)
plot(varImp.radomForest(modRF))
varImp.randomForest(modRF)
plot(varImp.randomForest(modRF))
varImp.RandomForest(modRF)
plot(varImp.RandomForest(modRF))
library(party)
varImp.RandomForest(modRF)
plot(varImp.RandomForest(modRF))
varImp(modRF)
plot(varImp(modRF))
varImp(modRF,scale = FALSE)
plot(varImp(modRF,scale = FALSE))
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF <- randomForest(y ~ ., data = vowel.train)
print(modRF)
vowel.test$y = factor(vowel.test$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
modRF1 <- train(y ~ ., data = vowel.train, method= "rf", trControl = trainControl(method = "cv"))
print(modRF)
importance(modRF)
importance(modRF1)
varImp(modRF)
importance(modRF1)
plot(varImp(modRF),varImp(modRF1))
par(mfrow = c(1,2))
plot(varImp(modRF))
plot(varImp(modRF1))
par(mfrow = c(1,2));varImpPlot(modRF);plot(varImp(modRF1))
library(ElemStatLearn); data(prostate)
str(prostate)
setwd("~/Desktop/2016/Data_science/Coursera_specialization/8_Practical_machine_learning/Project/Predictive_classification_of_human_activity_recognition_by_machine_learning/Predictive-classification-of-human-activity-recognition-by-machine-learning")
training <- read.csv("train.csv")
final_testing <- read.csv("test.csv")
summary(building)
# Decide what to do with the missing values
apply(is.na(building),2,sum) #  11548 data points (98% of them) are consistently missing in
length(which(apply(is.na(building),2,sum)>0)) # 67 variables
plot(building$classe[is.na(building$amplitude_pitch_forearm)]) # slightly more NA's in A class but #overall balanced distribution across the classes
##########################################
# STEP1: Drop the missing value containing variables as they are unlikely to add value to our #prediction (process the tune.testing, validation, final_testing sets exactly in the same way )
tune.testing <- tune.testing[,-which(apply(is.na(building),2,sum)>0)]
validation <- validation[,-which(apply(is.na(building),2,sum)>0)]
final_testing <- final_testing[,-which(apply(is.na(building),2,sum)>0)]
building <- building[,-which(apply(is.na(building),2,sum)>0)]
##########################################
# Find and remove near-zero variance variables
nsv <- nearZeroVar(x = building, saveMetrics = TRUE)
sum(!nsv$nzv) # 59 variables have non-zero variance and will be kept in the building set
##########################################
# STEP 2: Remove nzv variables, (process the tune.testing, validation and final_testing sets exactly in the same way #)
tune.testing <- tune.testing[,!nsv$nzv]
validation <- validation[,!nsv$nzv]
final_testing <- final_testing[,!nsv$nzv]
building <- building[,!nsv$nzv]
###########################################
# Next, let's have a look at the correlation between the continuous variables
cont <- !sapply(building,is.factor) # Continuous variables in the building set
M <- abs(cor(building[,cont])) # M is an absolute value correlation matrix representing the pairwise #correlations between all continuous variables
diag(M) <- 0 # We replace the diagonal values with zero (just because these are the correations with  #themselves we are not interested in capturing them).
which(M > 0.8, arr.ind = TRUE) # What are the highest correated variables?
unique(row.names(which(M > 0.8, arr.ind = TRUE))) # We find that there are 18 highly correlated #predictiors in the data set
qplot(building[,row.names(M)[7]],building[,colnames(M)[5]], color = classe, data = building)
qplot(building[,row.names(M)[8]],building[,colnames(M)[5]], color = classe, data = building)
plot(building[,row.names(M)[13]],building[,colnames(M)[5]])
plot(building[,row.names(M)[15]],building[,colnames(M)[6]])
plot(building[,row.names(M)[33]],building[,colnames(M)[40]])
qplot(building[,row.names(M)[33]],building[,colnames(M)[40]], color = classe, data = building)
cor.variables <- building[,unique(row.names(which(M > 0.8, arr.ind = TRUE)))]
cor.variables$classe <- building$classe
# Performing PCA to see if dimension reduction might help to resolve classes
prePCA <- preProcess(cor.variables[,-19],method = "pca")
PCAcor <- predict(prePCA,cor.variables[,-19])
qplot(PCAcor$PC1,PCAcor$PC2, color = classe, data = cor.variables)
qplot(PCAcor$PC1,PCAcor$PC3, color = classe, data = cor.variables)
qplot(PCAcor$PC2,PCAcor$PC3, color = classe, data = cor.variables)
# Not much obvious advantage gained by calculating principal components to seperate classes
# We notice that the correlated predictors have already clusters within them. In this case, I will not #attempt #further dimension reduction, because the data looks like suitable for classification algorithms (rather than linear #models)
######################################################################
# STEP3: Converting factor variables into dummy variables
which(sapply(building[,-59],is.factor)) # Only two factor variables remained in the datasets
# Note that one of them is a time stamp composed of 20 unique values. At this point we will model them as categorical variables
factors <- which(sapply(building[,-59],is.factor))
# Convert these variables into dummy variables:
dummies <- dummyVars(classe ~ user_name + cvtd_timestamp, data = building)
# Add them into building and all test and validation sets and drop the original factor variables
building <- cbind(building[,-factors],predict(dummies,building))
tune.testing <- cbind(tune.testing[,-factors],predict(dummies,tune.testing))
validation <- cbind(validation[,-factors],predict(dummies,validation))
names(final_testing)[59] <- "classe" # Names in newdata should match the object to use predict
final_testing <- cbind(final_testing[,-factors],predict(dummies,final_testing))
library(caret);library(ggplot2); set.seed(23445)
INbuilding <- createDataPartition(y = training$classe,p=0.6,list = FALSE)
building <- training[INbuilding,]
rest <- training[-INbuilding,]
INtune <- createDataPartition(y = rest$classe,p=0.5,list = FALSE)
tune.testing <- rest[INtune,]
validation <- rest[-INtune,]
summary(building)
# Decide what to do with the missing values
apply(is.na(building),2,sum) #  11548 data points (98% of them) are consistently missing in
length(which(apply(is.na(building),2,sum)>0)) # 67 variables
plot(building$classe[is.na(building$amplitude_pitch_forearm)]) # slightly more NA's in A class but #overall balanced distribution across the classes
##########################################
# STEP1: Drop the missing value containing variables as they are unlikely to add value to our #prediction (process the tune.testing, validation, final_testing sets exactly in the same way )
tune.testing <- tune.testing[,-which(apply(is.na(building),2,sum)>0)]
validation <- validation[,-which(apply(is.na(building),2,sum)>0)]
final_testing <- final_testing[,-which(apply(is.na(building),2,sum)>0)]
building <- building[,-which(apply(is.na(building),2,sum)>0)]
##########################################
# Find and remove near-zero variance variables
nsv <- nearZeroVar(x = building, saveMetrics = TRUE)
sum(!nsv$nzv) # 59 variables have non-zero variance and will be kept in the building set
##########################################
# STEP 2: Remove nzv variables, (process the tune.testing, validation and final_testing sets exactly in the same way #)
tune.testing <- tune.testing[,!nsv$nzv]
validation <- validation[,!nsv$nzv]
final_testing <- final_testing[,!nsv$nzv]
building <- building[,!nsv$nzv]
###########################################
# Next, let's have a look at the correlation between the continuous variables
cont <- !sapply(building,is.factor) # Continuous variables in the building set
M <- abs(cor(building[,cont])) # M is an absolute value correlation matrix representing the pairwise #correlations between all continuous variables
diag(M) <- 0 # We replace the diagonal values with zero (just because these are the correations with  #themselves we are not interested in capturing them).
which(M > 0.8, arr.ind = TRUE) # What are the highest correated variables?
unique(row.names(which(M > 0.8, arr.ind = TRUE))) # We find that there are 18 highly correlated #predictiors in the data set
qplot(building[,row.names(M)[7]],building[,colnames(M)[5]], color = classe, data = building)
qplot(building[,row.names(M)[8]],building[,colnames(M)[5]], color = classe, data = building)
plot(building[,row.names(M)[13]],building[,colnames(M)[5]])
plot(building[,row.names(M)[15]],building[,colnames(M)[6]])
plot(building[,row.names(M)[33]],building[,colnames(M)[40]])
qplot(building[,row.names(M)[33]],building[,colnames(M)[40]], color = classe, data = building)
cor.variables <- building[,unique(row.names(which(M > 0.8, arr.ind = TRUE)))]
cor.variables$classe <- building$classe
# Performing PCA to see if dimension reduction might help to resolve classes
prePCA <- preProcess(cor.variables[,-19],method = "pca")
PCAcor <- predict(prePCA,cor.variables[,-19])
qplot(PCAcor$PC1,PCAcor$PC2, color = classe, data = cor.variables)
qplot(PCAcor$PC1,PCAcor$PC3, color = classe, data = cor.variables)
qplot(PCAcor$PC2,PCAcor$PC3, color = classe, data = cor.variables)
# Not much obvious advantage gained by calculating principal components to seperate classes
# We notice that the correlated predictors have already clusters within them. In this case, I will not #attempt #further dimension reduction, because the data looks like suitable for classification algorithms (rather than linear #models)
######################################################################
# STEP3: Converting factor variables into dummy variables
which(sapply(building[,-59],is.factor)) # Only two factor variables remained in the datasets
# Note that one of them is a time stamp composed of 20 unique values. At this point we will model them as categorical variables
factors <- which(sapply(building[,-59],is.factor))
# Convert these variables into dummy variables:
dummies <- dummyVars(classe ~ user_name + cvtd_timestamp, data = building)
# Add them into building and all test and validation sets and drop the original factor variables
building <- cbind(building[,-factors],predict(dummies,building))
tune.testing <- cbind(tune.testing[,-factors],predict(dummies,tune.testing))
validation <- cbind(validation[,-factors],predict(dummies,validation))
names(final_testing)[59] <- "classe" # Names in newdata should match the object to use predict
final_testing <- cbind(final_testing[,-factors],predict(dummies,final_testing))
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 30))
View(building)
names(building)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 30))
make.names(names(building))
names(building) <- make.names(names(building))
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 30))
RPART
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 20))
RPART
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 100))
RPART
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "adaptive_cv", number = 100))
RPART
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "repeatedcv", number = 20))
RPART
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "LOOCV", number = 20))
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 10))
RPART
set.seed(1257)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 10))
RPART
set.seed(1257)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 10))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 10))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 5))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 15))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 9))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 8))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 10))
RPART
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 9))
RPART
set.seed(125745)
RF <- train(classe ~ ., data = building,method = "rf", trControl = trainControl(method = "cv", number = 9))
set.seed(125745)
RF <- train(classe ~ ., data = building,method = "rf") # Takes very long time to run!!
#set.seed(125745)
RF <- train(classe ~ ., data = building,method = "rf") # Takes very long time to run!!
set.seed(125745)
GBM <- train(classe ~ ., data = building,method = "gbm", trControl = trainControl(method = "cv", number = 9), verbose = FALSE) # Takes very long time to run!!
# Chunk 2
training <- read.csv("train.csv")
final_testing <- read.csv("test.csv")
# Chunk 3
nameframe <- data.frame(names(training),names(final_testing))
# Chunk 4
library(caret);library(ggplot2); set.seed(23445)
INbuilding <- createDataPartition(y = training$classe,p=0.6,list = FALSE)
building <- training[INbuilding,]
rest <- training[-INbuilding,]
INtune <- createDataPartition(y = rest$classe,p=0.5,list = FALSE)
tune.testing <- rest[INtune,]
validation <- rest[-INtune,]
# Chunk 5
summary(building)
# Decide what to do with the missing values
apply(is.na(building),2,sum) #  11548 data points (98% of them) are consistently missing in
length(which(apply(is.na(building),2,sum)>0)) # 67 variables
plot(building$classe[is.na(building$amplitude_pitch_forearm)]) # slightly more NA's in A class but #overall balanced distribution across the classes
##########################################
# STEP1: Drop the missing value containing variables as they are unlikely to add value to our #prediction (process the tune.testing, validation, final_testing sets exactly in the same way )
tune.testing <- tune.testing[,-which(apply(is.na(building),2,sum)>0)]
validation <- validation[,-which(apply(is.na(building),2,sum)>0)]
final_testing <- final_testing[,-which(apply(is.na(building),2,sum)>0)]
building <- building[,-which(apply(is.na(building),2,sum)>0)]
##########################################
# Find and remove near-zero variance variables
nsv <- nearZeroVar(x = building, saveMetrics = TRUE)
sum(!nsv$nzv) # 59 variables have non-zero variance and will be kept in the building set
##########################################
# STEP 2: Remove nzv variables, (process the tune.testing, validation and final_testing sets exactly in the same way #)
tune.testing <- tune.testing[,!nsv$nzv]
validation <- validation[,!nsv$nzv]
final_testing <- final_testing[,!nsv$nzv]
building <- building[,!nsv$nzv]
###########################################
# Next, let's have a look at the correlation between the continuous variables
cont <- !sapply(building,is.factor) # Continuous variables in the building set
M <- abs(cor(building[,cont])) # M is an absolute value correlation matrix representing the pairwise #correlations between all continuous variables
diag(M) <- 0 # We replace the diagonal values with zero (just because these are the correations with  #themselves we are not interested in capturing them).
which(M > 0.8, arr.ind = TRUE) # What are the highest correated variables?
unique(row.names(which(M > 0.8, arr.ind = TRUE))) # We find that there are 18 highly correlated #predictiors in the data set
qplot(building[,row.names(M)[7]],building[,colnames(M)[5]], color = classe, data = building)
qplot(building[,row.names(M)[8]],building[,colnames(M)[5]], color = classe, data = building)
plot(building[,row.names(M)[13]],building[,colnames(M)[5]])
plot(building[,row.names(M)[15]],building[,colnames(M)[6]])
plot(building[,row.names(M)[33]],building[,colnames(M)[40]])
qplot(building[,row.names(M)[33]],building[,colnames(M)[40]], color = classe, data = building)
cor.variables <- building[,unique(row.names(which(M > 0.8, arr.ind = TRUE)))]
cor.variables$classe <- building$classe
# Performing PCA to see if dimension reduction might help to resolve classes
prePCA <- preProcess(cor.variables[,-19],method = "pca")
PCAcor <- predict(prePCA,cor.variables[,-19])
qplot(PCAcor$PC1,PCAcor$PC2, color = classe, data = cor.variables)
qplot(PCAcor$PC1,PCAcor$PC3, color = classe, data = cor.variables)
qplot(PCAcor$PC2,PCAcor$PC3, color = classe, data = cor.variables)
# Not much obvious advantage gained by calculating principal components to seperate classes
# We notice that the correlated predictors have already clusters within them. In this case, I will not #attempt #further dimension reduction, because the data looks like suitable for classification algorithms (rather than linear #models)
######################################################################
# STEP3: Converting factor variables into dummy variables
which(sapply(building[,-59],is.factor)) # Only two factor variables remained in the datasets
# Note that one of them is a time stamp composed of 20 unique values. At this point we will model them as categorical variables
factors <- which(sapply(building[,-59],is.factor))
# Convert these variables into dummy variables:
dummies <- dummyVars(classe ~ user_name + cvtd_timestamp, data = building)
# Add them into building and all test and validation sets and drop the original factor variables
building <- cbind(building[,-factors],predict(dummies,building))
tune.testing <- cbind(tune.testing[,-factors],predict(dummies,tune.testing))
validation <- cbind(validation[,-factors],predict(dummies,validation))
names(final_testing)[59] <- "classe" # Names in newdata should match the object to use predict
final_testing <- cbind(final_testing[,-factors],predict(dummies,final_testing))
# Finally legitimize the names of the variables: (needed for the classification algorithms to run #smoothly)
names(building) <- make.names(names(building))
names(tune.testing) <- make.names(names(tune.testing))
names(validation) <- make.names(names(validation))
names(final_testing) <- make.names(names(final_testing))
# Chunk 6
set.seed(125745)
RPART <- train(classe ~ ., data = building,method = "rpart", trControl = trainControl(method = "cv", number = 9))
# Chunk 7
set.seed(125745)
RF <- train(classe ~ ., data = building,method = "rf", trControl = trainControl(method = "cv", number = 10)) # Takes very long time to run!!
# Chunk 8
set.seed(125745)
GBM <- train(classe ~ ., data = building,method = "gbm", trControl = trainControl(method = "cv", number = 10), verbose = FALSE) # Takes very long time to run!!
# Chunk 9
library(combinat)
lsmod = list ("rpart","gbm","rf","svm")
lsmod.combin = list(combn(lsmod,2),combn(lsmod,3),combn(lsmod,4)) # each column makes a prediction model fit
RF
GBM
tun <- predict(GBM,tune.testing)
confusionMatrix(tun,tune.testing$classe)
tun <- predict(RF,tune.testing)
confusionMatrix(tun,tune.testing$classe)
saveRDS(RPART,"RPART.rds")
saveRDS(RF,"RF.rds") #Save model object for future loading if necessary
saveRDS(GBM,"GBM.rds")
